{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6dd74b",
   "metadata": {},
   "source": [
    "## Image processing - segmentation and morphological operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167d6b5",
   "metadata": {},
   "source": [
    "This exercise sheet is based on the \"Synchrotron techniques for materials characterization\" lecture that was recorded for 26th January 2024. By going through this jupyter notebook and filling in the blanks you will learn how to assess basic properties of your image, perform simple image operations, assess the image quality quantitatively and apply a mean template filter.\n",
    "\n",
    "The example code and solutions were created by AndrÃ© Lopes Marinho and Berit Zeller-Plumhoff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd10be3",
   "metadata": {},
   "source": [
    "### Loading required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2054f08",
   "metadata": {},
   "source": [
    "You will require the following libraries. If loading any of them fails, please use pip install to install any missing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e3de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import ipympl\n",
    "import imageio.v3 as iio\n",
    "import skimage\n",
    "from skimage import draw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8dfb38",
   "metadata": {},
   "source": [
    "### Loading images and basic properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440283b0",
   "metadata": {},
   "source": [
    "The first task will be to write a function that will automatically load and display an image based on the image path that will be provided as an argument to the function.\n",
    "\n",
    "Please fill in the missing lines as indicated in the comments to load the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc860e11-3daf-4301-92b1-3978b70c7b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Magic Command that will ensure our images display in our Jupyter \n",
    "# document with pixel information that will help us to run commands more efficiently\n",
    "%matplotlib widget \n",
    "\n",
    "def load_and_show_image(path):\n",
    "    \"\"\"Loads and shows an image given a defined path.\n",
    "\n",
    "    Args:\n",
    "        path(string): String containing path for images with proper file extension. \n",
    "            Example: \"images/*.tif\"\n",
    "\n",
    "    Returns: \n",
    "        numpy.ndarray: Array with image defined in path.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We will use the skimage library to read our image\n",
    "    # use the iio.imread function to read in the image and use matplotlib to display in in greyscale\n",
    "    image = iio.imread(uri=path)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    print(path + ' was loaded successfully.')\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aab095",
   "metadata": {},
   "source": [
    "Once the image is loaded, we can assess it shape using the .shape command and the type of the image using the .dtype command. Find out what values the commands returns based on different example images that are provided in the test_images folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ede75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "\n",
    "img = load_and_show_image(path='test_images/A1_test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48dac2d",
   "metadata": {},
   "source": [
    "Write a short function that prints the image type, height, width and number of channels for any given input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41735934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image_props(image):\n",
    "    \"\"\"Displays image type, height, width and number of channels given an image.\n",
    "\n",
    "    Args:\n",
    "        image(variablename): variable name of an image\n",
    "    \"\"\"\n",
    "    # The method 'iio.imread' returns an numpy.ndarray, so we can perform array operations on the variable\n",
    "    # 'image', like showing the number of channels/depth of the image.\n",
    "    image_shape = image.shape\n",
    "    image_type = image.dtype\n",
    "\n",
    "    # With this information, we can also print some image properties\n",
    "    if len(image_shape) > 2:\n",
    "        print('Type =', image_type)\n",
    "        print('Height =', image_shape[0])\n",
    "        print('Width =', image_shape[1])\n",
    "        print('# of channels =', image_shape[2])\n",
    "    else:\n",
    "        print('Type =', image_type)\n",
    "        print('Height =', image_shape[0])\n",
    "        print('Width =', image_shape[1])\n",
    "        print('# of channels =', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='test_images/bone_16bit.png'\n",
    "img = load_and_show_image(path)\n",
    "print_image_props(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e6207b",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e14297c",
   "metadata": {},
   "source": [
    "In addition to assessing the general image properties, we are usually interested in knowing the greyscale distribution, i.e. the histogram, which gives us a first impression of image quality in terms of contrast and segmentability.\n",
    "\n",
    "In this following code snipped complete the function to evaluate and the histogram of an image that is input into the function as a numpy.ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee674a-aa96-439e-89b8-5871281a8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_histogram(image):\n",
    "    \"\"\"Showns an histogram given an image. This method considers the image will be\n",
    "        either grayscale or RGB\n",
    "\n",
    "    Args:\n",
    "        img(numpy.ndarray): Image represented by array\n",
    "\n",
    "    Returns: \n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, we need to know if the image is grayscale or RGB\n",
    "    # use the shape function to do so\n",
    "    image_shape = image.shape\n",
    "    image_type = image.dtype\n",
    "    \n",
    "    # Next, we can define some properties of our histogram figure\n",
    "    # create an empty figure with title, xlabel, ylabel and set the limits of the x-axis\n",
    "    plt.figure()\n",
    "    plt.title(\"Histogram\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Pixel count\")\n",
    "    plt.xlim([0, np.max(image)])\n",
    "        \n",
    "    # Finally, create a histrogram using the numpy histogram function and plot it\n",
    "    # use a bin number of 256 in all cases\n",
    "    if len(image_shape) > 2:\n",
    "        colors = (\"red\", \"green\", \"blue\")\n",
    "        for (channel_id, color) in enumerate(colors):\n",
    "            histogram, bin_edges = np.histogram(image[:, :, channel_id], bins=256, range=(0, np.max(image[:, :, channel_id])))\n",
    "            plt.plot(bin_edges[0:-1], histogram, color=color)\n",
    "    else:\n",
    "        histogram, bin_edges = np.histogram(image, bins=256, range=(0,np.max(image)))\n",
    "        plt.plot(bin_edges[0:-1], histogram)  \n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f89209",
   "metadata": {},
   "source": [
    "Now load a couple of test images and display their histogram using the functions you have adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2c32c-c93a-49f5-81a7-4e5b0d787d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "\n",
    "# Load an image and show its histogram\n",
    "\n",
    "img = load_and_show_image(path='test_images/bone_16bit.png')\n",
    "show_histogram(image=img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cac0ba",
   "metadata": {},
   "source": [
    "### Simple image operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4717f2f4",
   "metadata": {},
   "source": [
    "Once we are able to load an image and assess its properties as well as its histogram, we can perform a number of matrix operations on it.\n",
    "\n",
    "As shown as an example in the lecture, perform the following operation for the image $A$: $$A_{new}=\\frac{A}{4}+100$$ (make sure that the matrix dimensions fit).\n",
    "\n",
    "Use both the \"bone_16bit.png\" image and the \"A1_test.png\" image as input. Comment on how the image operation has changed the original image in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f541c5-4d98-494d-a2f3-e4cdc23b37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "\n",
    "img = load_and_show_image(path='test_images/A1_test.png')\n",
    "\n",
    "# perform the operation\n",
    "img_new = (img / 4) + 100 * np.ones((img.shape))\n",
    "\n",
    "# show the image and print the properties and show the histogram\n",
    "plt.imshow(img_new, cmap='gray')\n",
    "print_image_props(img_new)\n",
    "show_histogram(image=img_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb127a8",
   "metadata": {},
   "source": [
    "Similarly, as shown in the lecture perform the operation $$A_{new}=A*2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1155853",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "\n",
    "# perform the operation\n",
    "img_new = (img *2)\n",
    "\n",
    "# show the image and print the properties and show the histogram\n",
    "plt.imshow(img_new, cmap='gray')\n",
    "print_image_props(img)\n",
    "show_histogram(image=img_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc97ba2",
   "metadata": {},
   "source": [
    "In addition to adding or multiplying an image with scalars, we can add/subtract/multiply/divide images. This is a task performed often for example during the flat and dark field correction of projections prior to the 3D reconstruction of images.\n",
    "\n",
    "In the next task, please perform this correction of the projection \"proj.png\" in the test_images folder. In the same folder you will find the corresponding \"dark\" and \"flat\" image. Compare how the histogram of the projection changes due to the correction and comment on this based on what you observe qualitatively in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa32cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat and dark fiel corrections\n",
    "# load required images\n",
    "\n",
    "%matplotlib widget \n",
    "\n",
    "flat = load_and_show_image(path='test_images/flat.tiff')\n",
    "dark = load_and_show_image(path='test_images/dark.tiff')\n",
    "proj = load_and_show_image(path='test_images/proj.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1dd939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform correction operation and display the result\n",
    "%matplotlib widget \n",
    "\n",
    "proj_corr=(proj-dark)/(flat-dark)\n",
    "plt.imshow(proj_corr, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the histogram of the original and the corrected projection\n",
    "%matplotlib widget \n",
    "show_histogram(image=proj)\n",
    "show_histogram(image=proj_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318bfed",
   "metadata": {},
   "source": [
    "### Image quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7844bd",
   "metadata": {},
   "source": [
    "In addition to assessing the image histogram, we want to assess the image quality quantitatively. We can do so by calculating the signal-to-noise ratio (SNR) and contrast-to-noise ratio (CNR) for different regions of our image. In the following, you need to add missing code to two functions which will compuate SNR and CNR following the input of two image regions, respectively. We choose the following definitions of SNR and CNR: $$SNR = \\frac{S_i}{0.5\\sqrt{\\sigma_i^2+\\sigma_{bg}^2}}$$ and $$CNR = \\frac{|S_i-S_j|}{0.5\\sqrt{\\sigma_i^2+\\sigma_j^2}}$$\n",
    "where $S_i$ and $S_j$ are the mean greyscale values of the regions $i$ and $j$ and the respective $\\sigma$ the standard deviation of the greyscale values. For the SNR we attain the overall noise by taking into account the background noise too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a917861-ea99-4ca2-8d55-89ceec31e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signal_to_noise_ratio(region_i, region_bg):\n",
    "    \"\"\"Calculates Signal-to-Noise Ratio (SNR) by the following expression:\n",
    "    \n",
    "                SNR = |mean(region_i)| / 0.5*[sqrt(stdev(region_i)^2 + stdev(region_bg)^2)]                  \n",
    "                 \n",
    "    Args:\n",
    "        region_i(numpy.ndarray): Array slice defining region i\n",
    "        region_bg(numpy.ndarray): Array slice defining background region\n",
    "    Returns: \n",
    "        double: SNR value\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate the mean value of region_i\n",
    "    a = np.mean(region_i)\n",
    "    # calculate the denominator of the SNR\n",
    "    b = 0.5 * math.sqrt(np.std(region_i) ** 2 + np.std(region_bg) ** 2)\n",
    "    \n",
    "    # compute and return the SNR\n",
    "    SNR = a / b\n",
    "    \n",
    "    return SNR\n",
    "\n",
    "\n",
    "def get_contrast_to_noise_ratio(region_i, region_j):\n",
    "    \"\"\"Calculates Contrast-to-Noise Ratio (CNR) by the following expression:\n",
    "    \n",
    "                CNR = |mean(region_i) - mean(region_j)| / 0.5*[sqrt(stdev(region_i)^2 + stdev(region_j)^2)]                  \n",
    "                 \n",
    "    Args:\n",
    "        region_i(numpy.ndarray): Array slice defining region i\n",
    "        region_bg(numpy.ndarray): Array slice defining region j\n",
    "    Returns: \n",
    "        double: CNR value\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate the numerator of the CNR\n",
    "    a = abs(np.mean(region_i) - np.mean(region_j))\n",
    "    # calculate the denominator of the CNR\n",
    "    b = 0.5 * math.sqrt(np.std(region_i) ** 2 + np.std(region_j) ** 2)\n",
    "    \n",
    "    # compute and return the CNR\n",
    "    CNR = a / b\n",
    "    \n",
    "    return CNR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6dba5b",
   "metadata": {},
   "source": [
    "Based on the functions you have just created please calculate both SNR and CNR between the four quadrants of the image SNR_CNR.tif in the folder test_images. Overall, you should create four or six comparisons for SNR and CNR, respectively. To calculate the SNR you may assume that the darkest image quadrant is the background.\n",
    "\n",
    "In order to use the functions you must identify the regions within the image. Identify the image dimensions to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca85c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display the image\n",
    "\n",
    "%matplotlib widget \n",
    "\n",
    "SNRCNR = load_and_show_image(path='test_images/SNR_CNR.tif')\n",
    "\n",
    "# print image properties\n",
    "print_image_props(SNRCNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define four regions based on the image and its dimensions\n",
    "%matplotlib widget \n",
    "\n",
    "\n",
    "q1=SNRCNR[10:20,0:10]\n",
    "q2=SNRCNR[10:20,10:20]\n",
    "q3=SNRCNR[0:10,10:20]\n",
    "q4=SNRCNR[0:10,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a464646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all SNR and CNR\n",
    "\n",
    "SNR1=get_signal_to_noise_ratio(q1,q1)\n",
    "SNR2=get_signal_to_noise_ratio(q2,q1)\n",
    "SNR3=get_signal_to_noise_ratio(q3,q1)\n",
    "SNR4=get_signal_to_noise_ratio(q4,q1)\n",
    "\n",
    "CNR12=get_contrast_to_noise_ratio(q1,q2)\n",
    "CNR13=get_contrast_to_noise_ratio(q1,q3)\n",
    "CNR14=get_contrast_to_noise_ratio(q1,q4)\n",
    "CNR23=get_contrast_to_noise_ratio(q2,q3)\n",
    "CNR24=get_contrast_to_noise_ratio(q2,q4)\n",
    "CNR34=get_contrast_to_noise_ratio(q3,q4)\n",
    "\n",
    "# print the computed values\n",
    "print('SNR of Q1:',np.round(SNR1,2))\n",
    "print('SNR of Q2:',np.round(SNR2,2))\n",
    "print('SNR of Q3:',np.round(SNR3,2))\n",
    "print('SNR of Q4:',np.round(SNR4,2))\n",
    "\n",
    "print('CNR of Q1 vs Q2:',np.round(CNR12,2))\n",
    "print('CNR of Q1 vs Q3:',np.round(CNR13,2))\n",
    "print('CNR of Q1 vs Q4:',np.round(CNR14,2))\n",
    "print('CNR of Q2 vs Q3:',np.round(CNR23,2))\n",
    "print('CNR of Q2 vs Q4:',np.round(CNR24,2))\n",
    "print('CNR of Q3 vs Q4:',np.round(CNR34,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14efcdc1",
   "metadata": {},
   "source": [
    "Please comment on the values that you have obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea93b8f7",
   "metadata": {},
   "source": [
    "In the next task, use image \"A1_test2.png\" and calculate the CNR for root vs. soil, root vs. background and soil vs. background. Please comment on why you are selecting specific regions and comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53adfbe-8a40-4120-b61d-e3d77b2940cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "\n",
    "earth = load_and_show_image(path='test_images/A1_test2.png')\n",
    "\n",
    "print_image_props(earth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e62aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select different regions from the image and calculate SNR and CNR values\n",
    "\n",
    "# Regions\n",
    "air = earth[75:100, 185:210]\n",
    "soil = earth[75:100, 110:135]\n",
    "root = earth[55:75, 70:90]\n",
    "\n",
    "# Visualizing them on the image\n",
    "\n",
    "img_aux = earth.copy()\n",
    "\n",
    "row_air, col_air = skimage.draw.rectangle_perimeter(start=(75, 185), end=(100, 210))\n",
    "row_soil, col_soil = skimage.draw.rectangle_perimeter(start=(75, 110), end=(100, 135))\n",
    "row_root, col_root = skimage.draw.rectangle_perimeter(start=(55, 70), end=(75, 90))\n",
    "\n",
    "# For better vizualization\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img_aux, cmap = 'gray')\n",
    "ax.plot(col_air, row_air, '-r')\n",
    "ax.plot(col_soil, row_soil, '-g')\n",
    "ax.plot(col_root, row_root, '-b')\n",
    "\n",
    "# Calculate CNR\n",
    "\n",
    "# CNR - Soil and Root \n",
    "CNR1 = get_contrast_to_noise_ratio(soil, root)\n",
    "print('CNR soil vs. root: ', np.round(CNR1,2))\n",
    "\n",
    "# CNR - Soil and Air\n",
    "CNR2 = get_contrast_to_noise_ratio(soil, air)\n",
    "print('CNR soil vs. air: ', np.round(CNR2,2))\n",
    "\n",
    "# CNR - Air and Root \n",
    "CNR3 = get_contrast_to_noise_ratio(air, root)\n",
    "print('CNR air vs. root: ', np.round(CNR3,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0513c911",
   "metadata": {},
   "source": [
    "### Image filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d3024",
   "metadata": {},
   "source": [
    "If the image quality that we have determined is insufficient, e.g. if the CNR is particularly low, we can apply filters to improve the noise level while maintaining the sharpness of the features we are interested in. To do so, you will complete a function that defines a mean filter which is applied as a quadratic kernel template to the image. The function takes the original image and the filter kernel size as input and outputs the filtered image. You can move the template across the image in a scanning manner - in order to adjust for the edges correctly, you should apply a zero padding at the image borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d07af47-4b19-4c14-96bc-230595b241b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_filter(image, filter_size):\n",
    "    \"\"\"Applies mean filter in a given image.\n",
    "                 \n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be filtered\n",
    "        filter_size(numpy.ndarray): Size of kernel\n",
    "    Returns: \n",
    "        numpy.ndarray: Filtered image\n",
    "    \"\"\"\n",
    "    \n",
    "    temp = []\n",
    "    padding = filter_size // 2\n",
    "    img_final = np.zeros((image.shape))\n",
    "    \n",
    "    img_aux=np.zeros((image.shape[0]+padding*2,image.shape[1]+padding*2))\n",
    "    img_aux[padding:-padding,padding:-padding]=image.copy()\n",
    " \n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            temp=img_aux[i:i+filter_size,j:j+filter_size]\n",
    "            img_final[i][j] = np.mean(temp)\n",
    "            \n",
    "    return img_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f1caa",
   "metadata": {},
   "source": [
    "Apply the filter to the image \"A1_test2.png\" with different kernel sizes and plot both the original and the filtered image next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f28ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "### %matplotlib widget \n",
    "\n",
    "# earth = load_and_show_image(path='test_images/A1_test2.png')\n",
    "\n",
    "# Mean filter\n",
    "img_mean = mean_filter(earth, 3)\n",
    "\n",
    "# Plot your results to compare each one\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(earth, cmap='gray')\n",
    "ax2.imshow(img_mean, cmap='gray')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56b5e8",
   "metadata": {},
   "source": [
    "Finally, compute the CNR again for the regions your defined on the image previously and comment on how a mean filter with kernel size 3 has changed the CNR values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32eea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select different regions from the image and calculate SNR and CNR values\n",
    "\n",
    "# Regions\n",
    "air2 = img_mean[75:100, 185:210]\n",
    "soil2 = img_mean[75:100, 110:135]\n",
    "root2 = img_mean[55:75, 70:90]\n",
    "\n",
    "# Visualizing them on the image\n",
    "\n",
    "img_aux = img_mean.copy()\n",
    "\n",
    "row_air, col_air = skimage.draw.rectangle_perimeter(start=(75, 185), end=(100, 210))\n",
    "row_soil, col_soil = skimage.draw.rectangle_perimeter(start=(75, 110), end=(100, 135))\n",
    "row_root, col_root = skimage.draw.rectangle_perimeter(start=(55, 70), end=(75, 90))\n",
    "\n",
    "# For better vizualization\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img_aux, cmap = 'gray')\n",
    "ax.plot(col_air, row_air, '-r')\n",
    "ax.plot(col_soil, row_soil, '-g')\n",
    "ax.plot(col_root, row_root, '-b')\n",
    "\n",
    "# Calculate CNR\n",
    "\n",
    "# CNR - Soil and Root \n",
    "CNR1_mean = get_contrast_to_noise_ratio(soil2, root2)\n",
    "print('CNR soil vs. root after filtering: ', np.round(CNR1_mean,2))\n",
    "\n",
    "# CNR - Soil and Air\n",
    "CNR2_mean = get_contrast_to_noise_ratio(soil2, air2)\n",
    "print('CNR soil vs. air after filtering: ', np.round(CNR2_mean,2))\n",
    "\n",
    "# CNR - Air and Root \n",
    "CNR3_mean = get_contrast_to_noise_ratio(air2, root2)\n",
    "print('CNR air vs. root after filtering: ', np.round(CNR3_mean,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b331d31",
   "metadata": {},
   "source": [
    "In addition to the mean filter, we are interested in using the median and Gaussian filter. Write two functions that will apply the respective filter and output the filtered image, given a certain input image and kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "def median_filter(image, filter_size):\n",
    "    \"\"\"Applies median filter to a given image.\n",
    "                 \n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be filtered\n",
    "        filter_size(numpy.ndarray): Size of kernel\n",
    "        \n",
    "    Returns: \n",
    "        numpy.ndarray: Filtered image      \n",
    "    \"\"\"\n",
    "    temp = []\n",
    "    padding = filter_size // 2\n",
    "    img_final = np.zeros((image.shape))\n",
    "    \n",
    "    img_aux=np.zeros((image.shape[0]+padding*2,image.shape[1]+padding*2))\n",
    "    img_aux[padding:-padding,padding:-padding]=image.copy()\n",
    " \n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            temp=img_aux[i:i+filter_size,j:j+filter_size]\n",
    "            tmp_aux=np.reshape(temp, (filter_size**2))\n",
    "            tmp_aux.sort()\n",
    "            img_final[i][j] = tmp_aux[tmp_aux.shape[0] // 2]\n",
    "            temp=[]\n",
    "            \n",
    "    return img_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "def gaussian_filter(image, filter_size, sigma):\n",
    "    \"\"\"Applies median filter to a given image.\n",
    "                 \n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be filtered\n",
    "        filter_size(numpy.ndarray): Size of kernel\n",
    "        sigma(double): Standard deviation for Gaussian distribution\n",
    "        \n",
    "    Returns: \n",
    "        numpy.ndarray: Filtered image      \n",
    "    \"\"\"\n",
    "    temp = []\n",
    "    padding = filter_size // 2\n",
    "    img_final = np.zeros((image.shape))\n",
    "    \n",
    "    kernel = np.fromfunction(lambda x, y: (1 / (2 * math.pi * sigma ** 2)) * \\\n",
    "                             math.e ** ((-1 * ((x - (filter_size - 1) / 2) ** 2 + \\\n",
    "                                               (y - (filter_size - 1) / 2) ** 2)) / (2 * sigma **2)), (filter_size, filter_size))\n",
    "    \n",
    "    kernel /= np.sum(kernel)\n",
    "    \n",
    "    img_aux=np.zeros((image.shape[0]+padding*2,image.shape[1]+padding*2))\n",
    "    img_aux[padding:-padding,padding:-padding]=image.copy()\n",
    " \n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            temp=img_aux[i:i+filter_size,j:j+filter_size]\n",
    "            temp_aux = np.reshape(temp, (filter_size**2))\n",
    "            gauss = kernel.reshape((filter_size ** 2))\n",
    "            img_final[i][j] = np.sum(np.outer(temp_aux, gauss))\n",
    "            temp=[]\n",
    "            \n",
    "    return img_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd4c16",
   "metadata": {},
   "source": [
    "Apply the filters you have implemented so far to A1_test2.png using different filter parameters and comment on how the result changes and how the filters compare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd839d2",
   "metadata": {},
   "source": [
    "#### Fourier filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe64c7a2",
   "metadata": {},
   "source": [
    "In addition to the above filters, applying a Fourier filter, e.g. either a high-, low- or a bandpass filter can be very useful in order to highlight edges or smoothen the image. In the following, you should write three functions that will apply the different kinds of Fourier filters given an input image and the filter parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ce80f",
   "metadata": {},
   "source": [
    "Start by loading and displaying A1_test2.png - we will be working with this image in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fd4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "image = load_and_show_image(path='test_images/A1_test2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944d96a3",
   "metadata": {},
   "source": [
    "We will begin by applying a highpass filter - you will be required to use the image and the filter size as input to your function. Apply the 2d Fourier transform from numpy to your image and shift the resulting spectrum to the center of the image. You should then create a circular mask based on the filter size that sets all low frequencies, i.e. those in the center of the Fourier spectrum, to zero. Then perform the inverse Fourier operations (shifting the spectrum back first).\n",
    "\n",
    "Plot the original image, the magnitude spectrum, the highpass filter mask and the image after filtering next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4399f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_highpass_filter(image, filter_size):\n",
    "    \"\"\"Applies highpass Fourier filter to a given image.\n",
    "                 \n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be filtered\n",
    "        filter_size(numpy.ndarray): Number of frequency-equivalent pixels to remove\n",
    "        \n",
    "    Returns: \n",
    "        numpy.ndarray: Filtered image      \n",
    "    \"\"\"\n",
    "    # use the numpy 2D Fourier function to transform the input image\n",
    "    f = np.fft.fft2(image)\n",
    "    \n",
    "    # shift the spectrmu to the center\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "\n",
    "    # draw a cylindrical mask using the filter size to filter out the low frequencies\n",
    "    crow=fshift.shape[0]//2\n",
    "    ccol=fshift.shape[1]//2\n",
    "    rr, cc = skimage.draw.disk(center=(crow,ccol), radius=filter_size, shape=fshift.shape[0:2])\n",
    "    filter_img=np.ones((fshift.shape[0],fshift.shape[1]))\n",
    "    filter_img[rr, cc] = 0\n",
    "    fshift = fshift*filter_img\n",
    "    \n",
    "    # perform the inverse transform\n",
    "    f_ishift = np.fft.ifftshift(fshift)\n",
    "    img_back = np.fft.ifft2(f_ishift)\n",
    "    img_back = np.abs(img_back)\n",
    "\n",
    "    # Plot the original image, the magnitude spectrum, the highpass filter mask  \n",
    "    # and the image after filtering next to each other.\n",
    "    plt.subplot(141),plt.imshow(image, cmap = 'gray')\n",
    "    plt.title('Input image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(142),plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
    "    plt.title('Magnitude spectrum'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(143),plt.imshow(filter_img, cmap = 'gray')\n",
    "    plt.title('Highpass filter'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(144),plt.imshow(img_back, cmap = 'gray')\n",
    "    plt.title('Image after HPF'), plt.xticks([]), plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "               \n",
    "    return img_back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e20f869",
   "metadata": {},
   "source": [
    "Now use the function you have just defined on the image of the soil and root with different input filter sizes and comment on how the filter influences the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "image_fft=fft_highpass_filter(image, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bebd25",
   "metadata": {},
   "source": [
    "Next, define a function for a low-pass Fourier filter. Do the same as above, but maintain the low frequencies this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_lowpass_filter(image, filter_size):\n",
    "    \"\"\"Applies lowpass Fourier filter to a given image.\n",
    "                 \n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be filtered\n",
    "        filter_size(numpy.ndarray): Number of frequency-equivalent pixels to remove\n",
    "        \n",
    "    Returns: \n",
    "        numpy.ndarray: Filtered image      \n",
    "    \"\"\"\n",
    "    f = np.fft.fft2(image)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "\n",
    "    crow=fshift.shape[0]//2\n",
    "    ccol=fshift.shape[1]//2\n",
    "    rr, cc = skimage.draw.disk(center=(crow,ccol), radius=filter_size, shape=fshift.shape[0:2])\n",
    "    filter_img=np.zeros((fshift.shape[0],fshift.shape[1]))\n",
    "    filter_img[rr, cc] = 1\n",
    "    fshift = fshift*filter_img\n",
    "    f_ishift = np.fft.ifftshift(fshift)\n",
    "    img_back = np.fft.ifft2(f_ishift)\n",
    "    img_back = np.abs(img_back)\n",
    "\n",
    "    plt.subplot(141),plt.imshow(image, cmap = 'gray')\n",
    "    plt.title('Input image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(142),plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
    "    plt.title('Magnitude spectrum'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(143),plt.imshow(filter_img, cmap = 'gray')\n",
    "    plt.title('Lowpass filter'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(144),plt.imshow(img_back, cmap = 'gray')\n",
    "    plt.title('Image after LPF'), plt.xticks([]), plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "               \n",
    "    return img_back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ffc5a",
   "metadata": {},
   "source": [
    "Apply the low-pass filter to the image of the soil and root for different input filter sizes and comment on how the image is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f23bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "image_fft=fft_lowpass_filter(image, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2431517f",
   "metadata": {},
   "source": [
    "Finally, define a Fourier bandpass filter which takes two filter sizes as input for low- and high-frequency thresholds, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_bandpass_filter(image, filter_size1, filter_size2):\n",
    "    \"\"\"Applies bandpass fourier filter to a given image.\n",
    "                 \n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be filtered\n",
    "        filter_size1(numpy.ndarray): Number of frequency-equivalent pixels to remove fp\n",
    "        \n",
    "    Returns: \n",
    "        numpy.ndarray: Filtered image      \n",
    "    \"\"\"\n",
    "    f = np.fft.fft2(image)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "\n",
    "    crow=fshift.shape[0]//2\n",
    "    ccol=fshift.shape[1]//2\n",
    "    rr, cc = skimage.draw.disk(center=(crow,ccol), radius=filter_size2, shape=fshift.shape[0:2])\n",
    "    filter_img=np.zeros((fshift.shape[0],fshift.shape[1]))\n",
    "    filter_img[rr, cc] = 1\n",
    "    rr, cc = skimage.draw.disk(center=(crow,ccol), radius=filter_size1, shape=fshift.shape[0:2])\n",
    "    #filter_img=np.ones((new_img.shape[0],new_img.shape[1]))\n",
    "    filter_img[rr, cc] = 0\n",
    "    fshift = fshift*filter_img\n",
    "    fshift = fshift*filter_img\n",
    "    f_ishift = np.fft.ifftshift(fshift)\n",
    "    img_back = np.fft.ifft2(f_ishift)\n",
    "    img_back = np.abs(img_back)\n",
    "\n",
    "    plt.subplot(141),plt.imshow(image, cmap = 'gray')\n",
    "    plt.title('Input image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(142),plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
    "    plt.title('Magnitude spectrum'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(143),plt.imshow(filter_img, cmap = 'gray')\n",
    "    plt.title('Bandpass filter'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(144),plt.imshow(img_back, cmap = 'gray')\n",
    "    plt.title('Image after BPF'), plt.xticks([]), plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "               \n",
    "    return img_back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c593da3c",
   "metadata": {},
   "source": [
    "Apply the bandpass filter to the image of the soil and root for different input filter sizes and comment on how the image is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e888b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "image_fft=fft_bandpass_filter(image, 10,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2267e",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccfd04",
   "metadata": {},
   "source": [
    "In the following, you will become familar with a number of different methods for feature extraction, including thresholding and first and second order edge detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc1829",
   "metadata": {},
   "source": [
    "#### Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344433fa",
   "metadata": {},
   "source": [
    "To set sensible thresholds you should consider the histogram of an image after loading it. Load the the A1_test2.png image, apply a median filter and consider the histogram before and after filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c628c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d435852",
   "metadata": {},
   "source": [
    "Write a function that will threshold an input image within the range specified as input to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(image, low_thresh, up_thresh):\n",
    "    \"\"\"Applies a threshold to a given image.\n",
    "                 \n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be thresholded\n",
    "        low_thresh(scalar): Value of lower threshold\n",
    "        up_thresh(scalar): Value of upper threshold\n",
    "        \n",
    "    Returns: \n",
    "        numpy.ndarray: Thresholded image      \n",
    "    \"\"\"\n",
    "\n",
    "                   \n",
    "    return img_back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce4b14",
   "metadata": {},
   "source": [
    "You should see four peaks in the histogram of the filtered image. Apply the thresholding function for each of these peaks and plot the resulting images, as well as the input image, next to each other. Give each image a detail of what it represents.\n",
    "\n",
    "Play around with the performance of different image filters and kernel sizes and the regions you can subsequently segment using thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a73664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8033aa00",
   "metadata": {},
   "source": [
    "#### First order edge detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c806a",
   "metadata": {},
   "source": [
    "In first order edge detection, the gradient image of the original image is determined and local maxima are then identified. The resulting edge image may either be binary, i.e. already a thresholded version of the local maxima, depending on which step height should be included, or a greyscale image where each greyscale corresponds to the magnitude of the maximum.\n",
    "\n",
    "Because the process of implementing such a filter is complex, have a look here: https://towardsdatascience.com/canny-edge-detection-step-by-step-in-python-computer-vision-b49c3a2d8123\n",
    "and try to implement the filter and workflow given there in order to finally retrieve the edges between the soil and the air and the roots and the soil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf3f17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5be8fea7",
   "metadata": {},
   "source": [
    "### Morphological operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd87ac3",
   "metadata": {},
   "source": [
    "To easily clean up our image, we can use morphological operators, such as erosion and dilation. In the following, you should implement these as functions that take the binarized image and the kernel size for the (quadratric) operator as input and output the processed image.\n",
    "Keep in mind that you need to consider the image edges differently than during filtering, i.e. padding may not be appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9673d3d1",
   "metadata": {},
   "source": [
    "#### Erosion operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224b608",
   "metadata": {},
   "source": [
    "First, write a function to apply an erosion operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d1e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erosion_op(image, filter_size):\n",
    "    \"\"\"Applies erosion operator to a given binary image.\n",
    "                 \n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be processed, should contain only 0 and 1\n",
    "        filter_size(numpy.ndarray): Size of kernel\n",
    "    Returns: \n",
    "        numpy.ndarray: Filtered image\n",
    "    \"\"\"\n",
    "    \n",
    "    return img_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d3029e",
   "metadata": {},
   "source": [
    "Apply the erosion operator to the thresholded image of the root with different kernel sizes and comment on how the image changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e2a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f4bf09b",
   "metadata": {},
   "source": [
    "#### Dilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace76ea2",
   "metadata": {},
   "source": [
    "Now write a function for a dilation operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35381422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilation_op(image, filter_size):\n",
    "    \"\"\"Applies dilation operator to a given binary image.\n",
    "                 \n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be processed, should contain only 0 and 1\n",
    "        filter_size(numpy.ndarray): Size of kernel\n",
    "    Returns: \n",
    "        numpy.ndarray: Filtered image\n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "    return img_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f284b",
   "metadata": {},
   "source": [
    "Apply the dilation operator to the eroded image of the root with different kernel sizes and comment on how the image changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56788caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e043123c",
   "metadata": {},
   "source": [
    "Now plot original image next to the eroded and dilated one, as well as a dilated and eroded one. What differences do you see between the images if you apply kernel sizes of 3 and 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454dc19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e551c74c",
   "metadata": {},
   "source": [
    "### Distance transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef6510",
   "metadata": {},
   "source": [
    "Use the _scipy_ distance transform _distance_transform_ed_ and try to recreate the workflow shown in the lecture.\n",
    "Starting with the original image \"A1_test2.png\", filter it, threshold the soil and the root, try to clean the image as musch as possible and apply the distance transform to both images and by multiplying the output obtain the final image where you will have the distance to the root in all soil pixel.\n",
    "Plot the different intermediate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a3dee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
